# 빅데이터 분산컴퓨팅

[KOCW 강의](http://www.kocw.net/home/cview.do?cid=34cda35d03934785)

## Apache Hadoop (1차시)

### 하둡이란?

- 빅데이터를 저장, 처리, 분석할 수 있는 소프트웨어 프레임워크

- 구글에서는 여러 SW를 오픈소스로 제공하지만 빅데이터 프레임워크는 공개하지 않았음

- 아파치에서 만든 오픈 소스 프로젝트

- 특징

  1. Distributed : 수십만 대의 컴퓨터에 자료 분산 저장 및 처리
  2. Scalable : 용량이 증대되는 대로 컴퓨터 추가
  3. Fault-tolerant : 하나 이상의 컴퓨터가 고장나는 경우에도 시스템이 정상 동작
  4. Open source : 공개 소프트웨어

- 하둡과 관련된 다양한 생태계가 존재한다.

  hive, pig, hbase 등등...

  하둡 시스템을 프로그래머가 아닌 일반 유저들이 사용하기 쉽도록 만든 것 (java, scala 대신 sql로 프로그래밍 할 수 있도록 - hive)

### 하둡을 왜쓰냐

- 기존 large-scale 컴퓨팅 시스템의 문제점을 해결하기 위한 방안임

- 구글과 같이 대용량 데이터 처리를 하는 응용 분야 출현

- 구글이 90말 - 00초 부터 대용량 데이터 웹페이지 처리 위해서 프레임워크 관리하는 방식 - 발표함

  storage (GFix, 구글 파일 시스템?) / computation (map-reduce 방식 MR)

  → Open하지 않음

  만들게 된 동기는 근처에 있던 싼 pc 수만대 모아서 IBM main Frame 성능 따라가도록 하기 위해서임

- 구글의 방식을 보고 똑같이 처리할 수 있도록 따라한게 하둡임

  야후에서 아파치 진영에 많이 가서 같이 만듦

- 기존에는 더 빠른 프로세서와 메모리를 이용해서 처리 

  → Distributed

### 분산 처리 시스템

- 더 많은 컴퓨터를 사용하자
- 분산 처리 시스템의 진화
  - 하나의 작업에 여러 대의 머신을 사용
  - MPI (Message Passing Interface) 메시지 패싱이 너무 복잡하다. 그래서 좀 쉽게 처리하는 방법 필요함

## 2차시

### 분산 처리 시스템 문제점 (하둡 이전)

- 프로그래밍이 복잡함. sync 유지 힘들어

- 수많음 컴퓨터 사용하는데, 일부가 고장나면 동작하지 않음 (Partial failure)

  컴포넌트에서 failure 일어나면 애플리케이션 성능을 저하시킨다.

  1. 시스템은 반드시 Partial failure에 대한 대처가 필요하다. 작업이 지속적으로 수행되고, 어떤 데이터의 손실도 발생하면 안된다.

  2. 시스템의 컴포넌트 fail이후 다시 recover된 경우 전체 시스템 재시작 없이 rejoin 하는 것이 가능해야한다.
  3. 컴포넌트의 failure는 job의 결과에 영향을 주면 안된다.

- 그렇다면 

  3개의 copy를 만들어서 나눠서 가지고 있자.

  서버에서는 메타 데이타 (데이터 복사본이 어디 있는지의 위치)를 가지고 있음. 그걸로 복구

- Scalability에 대해서

  1. 데이터의 양이 증가하면 → 각 작업의 성능이 감소, 시스템이 fail 되지 X (시스템이 뻗어버린다면 scalable한 것이 아님) 

     Software framework가 지원해줘야 함, PC를 붙힐수록 퍼포먼스가 증가함

  2. 시스템의 resource를 증가 → 비례적으로 로드 capacity가 증가함

### 하둡의 역사

- 90-00 구글 연구에서 시작 

  GFS in 2003 / MapReduce in 2004

- 기존 분산 컴퓨팅의 문제점(reliability, scalability)문제를 모두 해결할 수 있는 새로운 접근법이다.

  고장났을 때 / 데이터 커졌을 때의 해결책 존재

- 초기 데이터를 시스템에 분산하여 저장하는 것이 핵심적인 개념임

  클러스터에 있는 각 노드가 로컬 데이터에 대한 작업을 처리한다.

  초기 프로세싱을 위해 네트워크 데이터 전송이 이루어지지 않음

### 하둡의 핵심 컨셉트

- 가능하면 쉽게 설계하자. "Easy to use"가 철학임

  CS 하는 사람 말고 다른 사람들도 편하게 쓸 수 있도록

  애플리케이션을 고수준 코드로 작성함

  (네트워크, 의존성, 저수준 인프라 구조에 대해서 고려하지 않아도 됨)

- 각 노드들은 가급적 최소한의 데이터를 주고 받는다. "Shared nothing" architecture

  개발자는 노드들 사이에 일어나는 통신에 대한 코드 작성이 필요 없슴

- 여러 노드에 데이터 분산저장 

  availability, reliability위해서 여러 복제본 존재

### 하둡 대강 훑어보기

- 시스템이 데이터 로드할 때 **블락**이라는 단위로 나눈다. (Storage)

  기본적으로 한 블락은 64MB or 128MB

- 계산은 **Map reduce** 방식을 사용한다. (Computation)

  (Map이라는 작업과 Reduce라는 작업이 있음 → Map task, reduce task 돌아가면서 일어남)

  Map tasks는 블락 하나 단위의 작업을 처리한다. 

- 분산되어 저장된 데이터 블락에 대해서 Map task 작업을 각 노드에 할당한다. 병렬적으로 작업 수행함.

### Fault Tolerance

- Node는 1대의 pc를 의미함 (CPU와 메모리를 가지고 있음)

- 노드 하나가 fail한 경우 마스터 노드가 감지하고 작업을 다른 노드에 할당한다. 

- Task를 재시작 하기 위해 다른 작업하던 다른 노드와의 통신이 필요하지 않음

  fail된 노드 재시작시 자동으로 시스템에 연결되고 새로운 task를 할당 받는다.

- 특정 노드가 성능이 낮다고 감지되면, 마스터 노드는 그 노드가 하던 같은 task를 다른 노드에 할당한다.

  → Speculative Execution

## 3차시, 4차시

### 하둡 설치 및 실행

- virtual box 깔아야 함니다

- 헐! 2021년부터 cloudera는 죄다 구독 형태로 유료화 되었다.. 강의만 들어야겠다 ㅠㅠ

  엥 아니다 리눅스에 이거 치면 trial 버전 받을 수 있다. 

  ![image](https://user-images.githubusercontent.com/41130448/115735517-8169a000-a3c5-11eb-8e1c-a47fcc291700.png)

  안돼에 404 뜬다... 안되나부다 ㅜㅜ

  ![image](https://user-images.githubusercontent.com/41130448/115735821-bece2d80-a3c5-11eb-9296-2ea01f2a1408.png)

- 암튼 실습 환경은 vm 에서 cloudera 이미지 받아서 적재해야 한다.

- Hue라는 웹 인터페이스가 있다. 데이터 분석을 제공한다.

### 하둡

- 시스템과 상호작용을 하기 위해서는 `hadoop`이라는 명령어를 통해서 한다.

- 하둡 명령어는 여러 개의 서브 시스템으로 세분화되어 있다. 

  예를 들면 HDFS의 파일을 처리하는 서브 시스템과, MapReduce Processing Job을 관리하고 실행하기 위한 서브 시스템이 있다. 

### HDFS 써보기

- HDFS와 관련된 서브 시스템은 `FsShell`이라고 한다. `hadoop fs` 명령어로 실행 가능하다.

- 로컬 머신 내에 하둡 VM이 깔린 상태이다. 로컬 머신 내의 disc과 하둡 내의 hdfs는 abstract하게 remote 되어 있는 것이다. 

- 로컬 컴퓨터에서 remote하게 액세스 하는것

- HDFS에 있는 파일을 보기 위해 쓰는 커맨드

  ```
  $ hadoop fs
  ```

  hdfs 클라우드를 관장하는 커맨드임

  ```
  $ hadoop fs -ls /
  ```

  HDFS의 root 디렉토리 내용 보기. 그 중 하나가 `/user`임

  개별 사용자는 `home` 디렉토리 아래에 사용자 이름으로 된 디렉토리가 있다.

  사용자의 홈 디렉토리는 `/user/training`이다. 

  ```
  $ hadoop fs -ls /user
  ```

  하둡 CDH 내의 HDFS에 접근하기

- HDFS의 디렉토리 구조와 로컬 파일 시스템의 디렉토리 구조는 연관성이 없다. 완전히 분리된 네임 스페이스라고 봐야 한다.

- 존재하지 않는 경로를 보여달라고 요청하면 에러 메시지가 뜬다.

  ```
  $ hadoop fs -ls /foo
  ```

- 기존의 파일 시스템을 탐색하는 것 외에 `FsShell`로 할 수 있는 또 다른 중요한 점

  HDFS에 새로운 데이터를 업로드 하는 것

  로컬에서 데이터를 준비한 후 HDFS에 올려줘야 한다. 

  VM 내에 local 영역과 HDFS 영역이 있는데 local 영역에서 HDFS 영역으로 파일을 올려준다.

  ```
  $ cd ~/training_materials/deveolper/data
  ```

  요기에 `shakespeare.tar.gz` 등의 여러 개의 파일이 있다.

  ```
  $ cd ~/training_materials.tar.gz
  ```

  로컬에서 압축을 풀고 (`shakespeare`라는 디렉토리 생성됨)

  ```
  $ hadoop fs -put shakespeare /user/training/shakespeare
  ```

  그 녀석을 HDFS 상에 복사한다. (HDFS에서 로컬로 가져오려면 `-get` 쓴다)

  ```
  $ hadoop fs -ls /user/training
  ```

  데이터가 올라갔는지 확인

  ```
  $ hadoop fs -ls
  ```

  다시 명령어를 이렇게 치면 동일한 결과가 나온다. 디렉토리 명을 따로 입력하지 않으면 `home` 디렉토리인 `/user/training`을 입력했다고 간주한다.

  ```
  $ hadoop fs -mkdir weblog
  ```

  디렉토리 새로 만들기

  추후 실습 파일 중 Gzip을 통해 압축되어 있는 웹 서버 로그 파일이 있다. 이 파일을 로컬에서 해제하지 말고 압축 해제와 업로드를 한번에 하기 위해 폴더를 미리 생성

  ```
  $ gunzip -c access _log.gz\
  | hadoop fs -put - weblog/access_log
  ```

  `Gunzip`에 `-c` 옵션으로 표준 출력으로 압축 해제 후 `-put` 명령어로 HDFS에 데이터 올리기

  ```
  $ hadoop fs -ls
  ```

  아파치 로그 파일이 HDFS 상의 home 디렉토리에 올라간 것을 확인

13 : 28
# 데이터 중심 애플리케이션 설계

<br>

애플리케이션 개발 과정의 변화

- CPU 클럭 속도는 거의 증가하지 않고 있음. 멀티코어  프로세서가 표준이 되었고 네트워크는 빨라지고 있음. 이와 함께 병렬 처리가 늘어나고 있다.
- IaaS 덕분에 쉽게 분산 시스템 개발 및 다양한 지역에 구축 가능
- 사람들은 서비스 제공에 더 높은 기준을 요구함. 서비스 중단 시간을 용납하지 못함

애플리케이션을 두 가지로 나누어 볼 수 있다.

1. 데이터 중심 애플리케이션

   데이터가 주요 challenging한 요소인 경우

2. 계산 중심 애플리케이션

   CPU 사이클이 병목인 경우

<br>

## 1장 데이터 시스템의 기초

## 01 *신뢰*할 수 있고 *확장 가능*하며 *유지보수*하기 쉬운 애플리케이션

- 오늘날 많은 애플리케이션은 데이터 중심적임. 문제가 되는 요소는 데이터의 양, 복잡도, 변화 속도이다.
- 애플리케이션이 필요로 하는 것 : 데이터베이스, 캐시, 검색 색인, 스트림 처리, 일괄 처리
- 애플리케이션마다 요구사항이 다르므로 DB 시스템도 다양한 특성이 있다.
- 신뢰성, 확장성, 유지보수성의 의미를 명확히 하자. 그리고 이를 고려하는 방법을 알아보자.

<br>

### 데이터 시스템에 대한 생각

- 데이터베이스, 큐, 캐시 등은 서로 다른 접근과 성능 특징을 가지고 있지만 데이터 시스템이라는 이름으로 퉁치는 이유

  1. 새로 생긴 툴들은 전통적인 분류에 잘 맞지 않음, 분류 간 경계가 흐림

     예) 레디스(메시지 큐로 사용하는 데이터스토어), 아파치 카프카(지속성을 보장하는 메시지 큐)

  2. 많은 애플리케이션들의 요구사항이 넓고 깊어짐. 데이터 처리와 저장을 모두 만족시킬 수 없음. 작업을 태스크로 나누고, 애플리케이션 코드를 이용해 연결한다.

     예) 인메모리 캐시, 전문 검색 서버 등을 따로 사용하며 동기화 유지

  → 개발자는 이제 애플리케이션 설계 뿐만 아니라 데이터 시스템도 함께 설계 해야 함

- 신뢰성, 확장성, 유지보수성 중심으로 살펴볼 것이다. 용어의 의미를 명확히 이해하고 엔지니어링 관점에서 생각해보자.

<br>

### 신뢰성

- 하드웨어, 소프트웨어 결함, 인적 오류에도 시스템이 **원하는 성능 수준에서 지속적으로 올바르게 동작**하는 것

- 결함과 장애는 동일하지 않다. 장애는 시스템 전체가 멈추어 사용자에게 서비스를 제공하지 못하는것

  결함으로 인해 장애가 일어나지 않도록 설계하는 것이 좋다.

- 고의적으로 결함을 유도해서 시스템이 잘 대처하도록 훈련할 수도 있다. (넷플릭스의 카오스 몽키)

  > 1. 시스템의 “정상 상태”를 정의해 정상 동작의 기준선을 설정한다.
  >
  > 2. 대조군과 실험군 양쪽에서 모두 이 정상 상태가 계속된다는 가설을 세운다.
  >
  > 3. 서버 멈춤, 하드 드라이브 고장, 네트워크 연결 끊김과 같은 실제 상황을 반영하는 변수를 도입한다.
  >
  > 4. 대조군과 실험군 사이의 차이점을 확인해 가설이 틀렸음을 입증한다.

- 보안 문제에서는 결함을 예방하는 것이 매우 중요하다. 

- 해결책을 마련할 수 있는 결함 유형을 다뤄보자.

<br>

1. 하드웨어 결함
   - 하드웨어의 결함은 대체로 무작위적으로 독립적이다. 온도와 같은 약한 상관관계가 있을 수는 있지만 보통 여러 구성 요소에서 동시 다발적으로 장애가 생기지는 않는다.
   
   - 하드디스크에서 장애가 발생하는 평균 시간은 10~50년이다. 10,000개의 디스크로 구성된 저장 클러스터라면 평균적으로 하루에 하나의 디스크가 죽는다고 생각하면 된다.
   
   - 대응 방법은 각 하드웨어 구성 요소에 중복을 추가하는것
   
     > 이중 전원 디바이스, hot-swap이 가능한 CPU, 예비 디젤 발전기 갖추기 등
   
   - 데이터 양과 계산 요구가 늘면서 더 많은 장비가 사용된다. 이에 비례해서 하드웨어 결함률도 증가함
   
     AWS같은 클라우드 플랫폼은 별도의 경고 없이 가상 인스턴스가 사용 불가상태가 된다. 
   
     > 애초에 설계할 때 단일 장비 신뢰성보다 유연성, 탄력성을 우선적으로 처리하게끔 되어 있음
   
   - 암튼 소프트웨어 내결함성 기술 + 하드웨어 중복성으로 전체 장비의 손실을 견딜수 있게 시스템화 하고 있다.
   
     한번에 한 노드씩 패치하여 업그레이드할 수도 있다.
   
2. 소프트웨어 오류

   - 시스템 내의 체계적 오류 같은 것이다. 

   - 특정 상황에 의해 발생하기 전까지 오래 나타나지 않으므로 예상하기 어렵다.

     노드 간의 상관관계 떄문에 (서로 독립적인) 하드웨어보다 시스템 오류를 더욱 많이 유발하는 경향이 있다.

     > 예시
     >
     > - 잘못된 특정 입력 시 모든 서버 인스턴스가 죽는 버그. 리눅스 커널의 2012.06.30 윤초 오류
     > - CPU, 메모리, 디스크, 네트워크 대역폭처럼 공유 자원을 과도하게 사용하는 일부 프로세스
     > - 시스템의 속도가 느려져 반응이 없거나 잘못된 응답을 반환하는 서비스
     > - 연쇄 장애 (cascading failure)

   - 신속한 해결책이 없다. 다음과 같은 것들로 최대한 예방 해야 한다.

     → 시스템의 가정과 상호작용에 대해 주의 깊게 생각, 빈틈없는 테스트, 프로세스 격리, 죽은 프로세스의 재시작 허용, 프로덕션 환경에서 시스템 동작의 측정, 모니터링, 분석하기, 시스템이 보장하길 바라는 어떤 것에 대해 수행 중 지속적으로 확인하고 차이가 생기는 경우 경고 발생시키기

3. 인적 오류

   - 사람은 미덥지 않지만 (ㅋㅋ) 시스템을 신뢰성 있게 만들어야 한다.

   - 접근 방식들

     → 추상화, API, 관리 인터페이스를 잘 설계해야함 오류의 가능성을 최소화하도록 (하지만 또 지나치게 제한적이면 안됨)

     → 비 프로덕션 샌드박스를 제공하자. 사람의 실수로 장애가 발생할 수 있는 부분을 분리해서 실 사용자에게 영향이 미치지 않게 실험하도록.

     → 철저한 테스트 : 단위 테스트, 전체 시스템 통합 테스트, 수동 테스트, 자동 테스트, 코너 케이스 체크

     → 롤백, 롤아웃, 데이터 재계산 도구 등을 사용해서 복구가 빨리 되도록 한다.

     → 상세하고 명확한 모니터링 : 성능 지표, 오류율 확인

     > 모니터링을 원격 측정(telemetry)라고 부르기도 한다.
     >
     > 문제 발생 시 지표(metrics)는 문제 분석 시 매우 중요하다

     → 조작 교육과 실습을 시행하라. 까다롭지만 중요하다.

4. 그래서

   신뢰성은 중요하다.

   비용을 줄여서 신뢰성을 희생하는 경우가 있지만 그게 어디까지 허용되는지 잘 알아야 한다.

<br>

### 확장성

- 현재의 안정적인 동작이 미래의 안정성을 보장하지 않는다.

- 성능 저하의 가장 흔한 이유는 부하 증가다.

- 확장성은 부하 증가하는 것에 대처하는 시스템 능력이지만, 일차원적인 표식이 아니다.

  확장성을 논한다는건 *A는 확장 가능하다. 확장성이 없다* 따위가 아니라, *시스템이 특정 방식으로 커지면 이에 대처하기 위한 선택은 무엇인가?, 추가 부하를 다루기 위해 계산 자원을 어떻게 투입할까?*와 같은 것을 고려하는 것이다.

1. 부하 기술하기

   - 시스템의 부하를 간결하게 기술해야 부하가 성장했을때의 논의를 진행할 수 있다.

   - 그래서 부하를 어떻게 나타내냐? 

     → 부하 매개변수를 사용

   - 적합한 부하 매개변수는 시스템 설계에 따라 달라진다. (진리의 케바케)

     > 웹 서버의 초당 요청 수, 데이터베이스의 읽기 대 쓰기 비율, 대화방의 동시 활성 사용자, 캐시 적중률 등

   - 평균적인 경우가 중요할 수도 있고 소수의 극단적인 경우가 병목 현상의 원인일 수도 있다.

     > ~~정말 딱 공통적인 시나리오 상황은 거의 없고 서비스나 실제 시스템 상황을 잘 연구하고 고려해야 되는구나 하는 생각이 든다~~

   - 트위터 사례

     - 트위터의 주요 동작
       1. 트윗 작성 : 팔로워에게 새로운 메시지를 게시 (평균 초당 4.6K 요청, 피크 시 초당 12K이상)
       2. 홈 타임라인 : 팔로우한 사람이 작성한 트윗 보기(평균 초당 300K 요청)
     - 단순한 초당 12K 작성 요청 처리는 쉽다. 그러나 확장성에서 발생하는 문제는 트윗 양보다는 팬아웃이다.

2. 성능 기술하기

3. 부하 대응 접근 방식

<br>

### 유지보수성

1. 운용성: 운영의 편리함 만들기
2. 단순성: 복잡도 관리
3. 발전성: 변화를 쉽게 만들기

### 정리

<br>

## 02 데이터 모델과 질의 언어

<br>

## 03 저장소와 검색

<br>

## 04 부호화와 발전

<br>

## 2장 분산 데이터

<br>

## 05 복제

<br>
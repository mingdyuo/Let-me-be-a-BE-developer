# 우아한 레디스

[[우아한 테크 세미나] 우아한 레디스](https://www.youtube.com/watch?v=mPB2CZiAkKM)

## Redis 운영

### 메모리 관리

- 큰 메모리를 사용하는 instance 하나보다는 적은 메모리를 사용하는 instance 여러 개가 안전하다.

  24 GB < 8 + 8 + 8 GB

- Write가 heavy 한 경우에는 최대 메모리를 2배까지 쓸 수 있다. 

  처음에 fork를 했을 때에는 copy on write라고 해서 read만 하면 복사하지 않고, write가 일어나면 복사해서 더 써야 함. 이론적으로는 1.몇배에서 2배까지 쓸 수 있음 

- 메모리를 나누어 놓으면 관리하기는 귀찮지만 운영의 안정성은 더 높아진다. 굳이 쓰고 있는 것을 바꿀 필요는 없다. 

- 메모리 파편화가 발생할 수 있다. 

  `max memory` 설정하더라도 allocator 구현에 따라서 성능이 왔다갔다 할 수 있다. (jemalloc 사용)

  레디스는 사용하고 있는 메모리 양을 정확하게 알 수 없다. 해제했다고 하지만, 붙잡고 있을 수도 있음.

  - 3.x대 버전의 경우 실제 used memory는 2GB로 보고되지만, 11GB의 RSS를 사용하는 경우가 자주 발생했다. 
  - 4.x 버전부터 메모리 파편화 줄이도록 jemalloc에 힌트 주는 기능이 들어갔으나 jemalloc 버전에 따라서 다르게 동작할 수 있다. 

- 다양한 사이즈를 가지는 데이터 보다는 유사한 크기의 데이터를 가지는 경우가 유리하다. 메모리 파편화를 덜 일어나게 한다. 

### 메모리가 부족할 때는

- 캐시는 다 돈이다.
  - 좀더 메모리가 많은 장비로 migration 
  - 메모리가 빡빡하면 migration 중에 문제가 발생할 수도 있음. 70% 이상 쓰고 있으면, 메모리 업그레이드를 고려해야 한다. 
- 있는 데이터를 줄이기
  - 데이터를 일정 수준에서만 사용하도록 특정 데이터를 줄인다.
  - 만약 이미 swap을 사용중이라면, 프로세스를 재시작해야 한다. 

### 메모리를 줄이기 위한 설정

- 기본적으로 collection들은 다음과 같은 자료구조를 사용한다. 

  - Hash는 내부적으로 hash table을 하나 더 쓴다. 

  - Sorted set은 skiplist와 Hash table을 사용한다. 

    값으로도 찾아야 하고, 인덱스로도 찾아야 하기 떄문

  - Set도 Hash Table 사용

  이 자료구조들은 우리가 생각하는 것보다 메모리를 많이 쓴다. 포인터 할당, 메모리 단편화 일어날 확률 증가. 

- ziplist

  아이템 개수를 한 컬렉션에 몇십개, 몇백개 사용한다면 ziplist를 쓰는게 속도는 조금 느려지더라도 메모리를 훨씬 적게 쓴다.

  자료구조를 저장할 때 원래 쓰는 구조 대신 내부적으로 ziplist를 쓰도록 설정 바꿔야 한다. 

### Ziplist 

- In memory 구조상, 적당한 사이즈까지는 특정 알고리즘을 안쓰고 선형 탐색을 하더라도 빠른 편이다. 

  퀵 소트 최적화를 보면, 알고리즘 잘 만드는 것도 중요하지만, 마지막 100개 이내에서는 insert search를 사용해서 소트 시키는게 빠르다고 한다.

- List, hash, sorted set 등을 ziplist로 대체해서 처리하는 설정이 존재한다.

  `{DS}-max-ziplist-entries` -> 개수 몇개까지는 ziplist를 쓰겠다. 

  `{DS}-max-ziplist-value` -> value 얼마까지는 쓰겠다. 

- 100개 정도로 원소가 적으면 알고리즘 쓰는것과 비슷하게 빠르다.

- 메모리 사용량 2-30% 차이까지 날 수 있다. 

### O(N) 관련 명령어는 주의하자.

- Redis는 Single threaded이다.

  - 동시에 처리할 수 있는 명령 개수는 한번에 1개임

  - 단순한 get/set의 경우 초당 10만 TPS 이상 가능 (CPU 속도에 영향을 받는다.)

    1개의 요청이 1초 걸린다면 최악의 경우 9만9999개의 명령은 1초동안 대기해야 함. 죄다 타임아웃 날것이다. 서비스 터질 수 있다.

- packet이 다음 순서로 들어온다.

  1. `processInputBuffer`
  2. `processCommand`

  Packet으로 하나의 command가 완성되면, `processCommand`에서 실제로 실행된다. 처리되는 동안에는 다른 패킷이 쌓인다. 패킷이 커맨드로 실행되어 루프에서 탈출해야 다음 패킷이 처리된다. 

- 대표적인 O(N) 명령들 - 실수 많이 하는 사례들

  - KEYS - 모든 키 가져오기

    - Key가 백만개 이상인데, 확인을 위해서 명령을 사용하는 경우 (모니터링 스크립트가 계속 호출)
      - `scan` 이라는 명령으로 대체 가능. 짧은 여러 번의 명령 사용. 텀 사이사이에 GET, SET 같은 다른 명령이 실행될 수 있다. 
      - 스캔은 커서 방식을 사용하고 있음. 짧게 여러 번 돌리는 형태
      - 최종 커서 값이 0이 돌아올 때까지 돌리는 것.
    - 아이템이 몇만개 들어있는 hash , sorted set, set에서 모든 데이터를 가져오는 경우

  - FLUSHALL, FLUSHDB

    데이터 다날리기. 

  - Delete collections

    - 백만개 있는거 지우면 1-2초 걸린다. 그러면 1-2초 동안 아무것도 못함

  - Get All Collections (Collection의 모든 item을 가져와야 할 때?)

    - collection의 일부만 가져오자. Sorted set은 부분을 끊어 가져올 수 있음. 

    - 큰 Collection을 작은 여러 개의 Collection으로 나눠서 저장.

    - Collection 한개당 몇천개 안쪽으로 저장하는 게 좋음. 

  - 예전의 Spring security oauth `RedisTokenStore`

    Access Token의 저장을 List(O(N)) 자료 구조를 통해서 이루어진다.

    - 검색, 삭제 시에 모든 item을 매번 찾아봐야 한다. 100만개 정도 되면 전체 성능에 영향.
    - 현재는 Set(O(1))을 이용해서 검색, 삭제를 하도록 수정되어 있다. 

  - O(1), O(N) 명령을 구분하고, O(N)은 가능한 최대한 피하자.

### Redis Replication

- 레디스의 장점 중 하나
  - A 서버의 데이터를 B 서버도 똑같이 들고 있을 수 있음
- 레디스 복제는 Async임, Lag이 발생할 수 있음
  - 복제하는 틈 사이에 A와 B의 데이터가 달라질 수 있음
  - 마스터에 써졌는데 slave에 없는 데이터 있을 수 있음
  - 거의 발생하지 않을 것 같지만 부하에 따라서 발생할 수도 있음
  - 렉이 많이 벌어지면 slave가 커넥션 끊고 다시 연결할 수 있음
    - 그 때 부하가 많이 늘어날 수 있다.
  - 5.0.0 이상이면 `Replicaof` , 그 이전이면 `slaveof` 명령으로 설정할 수 있다. (slave-master에서 replica-original로 이름이 바뀜)
    - `Replicaof {hostname} {port}`
  - DBMS로 보면 statement replication이 유사함
- row replication 이 아니고 쿼리 replication임
  - 쿼리로 보낼때의 차이
  - now라는 펑션을 쓰면 primary, secondary 실행되는 경우 달라질 수 있다. 
  - 평소에 문제 없다가 lua script 쓰면 경우에 따라 다른 값이 나올 수 있다.
- replication 설정 과정
  - Secondary에 명령 전달 (`replicaof` , `slaveof`)
  - 내부적으로 secondary는 primary에 sync 명령 전달 
  - primary는 현재 메모리 상태 저장하기 위해서 fork함 (만악의 근원이지만 지금 고쳐질수는 없음ㅋ)
    - fork한 프로세서는 현재 메모리 정보를 disk에 dump 한다.
    - 해당 정보를 secondary에 전달한다.
    - fork 이후의 데이터를 secondary에 계속 전달한다. 그러면서 replication이 계속 되는 것
  - stream으로 바로 보내는 disk less 방식도 있음
    - 이걸 쓰면 disk io는 줄어드나 메모리의 사용량은 쫌 있어서, 여전히 이슈 발생할 수 있다.
- 주의할 점
  - 메모리 헤비하게 쓰면 fork 할 때 레디스가 다 죽어버릴 수도 있다. ㄷㄷ
  - `redis-cli --rdb` 
    - 현재 상태의 메모리 스냅샷을 가져옴
    - 같은 문제 발생시킬 수 있음. 포크하다가 죽을 수 있다.
  - 직접 설치하는 경우 말고, 아마존 같은 클라우드의 레디스는 fork 없이 replication 데이터 전달하는 기능 있을 수도 있음. 안정적인 대신 좀 많이 느리다. 
  - 많은 대수의 redis 서버가, 많은 replica를 두고 있는 경우
    - 네트웤 이슈나, 사람의 작업으로 동시에 replication이 새로 일어나지 않도록 조심해야 한다. 
    - 동시에 재시도 되면 문제 발생 가능함
    - 네트워크 bandwidth 보다 많은 양을 전달해야 하는 경우가 생길 수 있음 
      - 레디스 백대 있고 256기가 인스턴스인데 slave로 연결시킨 경우
      - 그런 경우 백대가 256기가 보낼라고 네트워크 다 쓰잖슴
      - 네트웍 마비되서 끊어져서 다시뜨고, 끊어져서 다시뜨고 할 수 있음. 그런 경우 예상해서 수동으로 한대씩 띄우던가 하는 방식 취해야 함 

### 권장 설정

- Maxclient 값을 높이세요. 50000
  - 이 값만큼 네트웍으로 접속할 수 있음
  - 체크 위해서 접속하고 싶은데 접속 안되는 경우가 있음
- RDB/AOF 설정 끄는 것이 성능, 안정성상 더 유리하다.
- 특정 커맨드는 disable 가능
  - Keys는 가능한 무조건 disable 시켜라
  - AWS, ElasticCache에서는 이미 몇 커맨드 disable되어 있음. 
- 전체 장애의 90% 이상이 KEYS와 SAVE 설정을 사용해서 발생한다. (rdb 디폴트 설정 등)
  - SAVE : 1분 안에 key가 만개가 바뀌었어. 그러면 메모리를 덤프해, 이런 설정
    - 서비스에 나가보면 1분에 만개 업데이트 되는 케이스가 굉장히 많음
    - 디스크에 32기가씩 1분당 쓴다고 생각하면, 폭파된당
  - 마스터에서는 무조건 꺼놔라

### Redis 데이터 분산 

- 데이터의 특성이 중요함

  - 캐시로 쓰냐 persistent store로 쓰냐에 따라 다르다. 
  - 캐시로 쓰면 우아할 수 있음
  - persistent 해야 하면 안우아해짐

- 데이터 분산 방법

  - 어플리케이션 레벨
    - Consistent hashing
      - modular 방식을 사용하면 (골고루 부하를 분산할 수 있지만) 서버가 새로 추가되거나, 장애로 제외되었을 때 리밸런싱이 일어나서 데이터의 이동이 많이 일어나야 한다. 
      - 해시 값을 계산해서 자기 값보다 큰데 가장 가까운 쪽으로 이동
      - twemproxy를 사용하는 방법으로 쉽게 사용 가능하다. 
    - sharding
      - 데이터를 어떻게 나눌 것인가? = 데이터를 어떻게 찾을 것인가?
      - 하나의 데이터를 모든 서버에서 찾아야 하면? 
        - 모든 서버에 찾아야 하면 부하
        - 한번에 어느 서버로 갈지 알아야 함
      - 상황마다 샤딩 전략이 달라진다.
        - 가장 쉬운 방법은 서버당 range를 정의하는 것
          - 놀고 있는 서버, 안노는 서버가 발생할 수 있음
        -  modular
          - 균등 분배 가능
        - 해당 key가 어디에 저장되어야 하는지 알려주는 관리서버를 따로 만들 수 있음 (Index server)
          - 인덱스 서버가 죽으면 서비스 죽을 수 있다.
  - 레디스 클러스터 레벨
    - CRC16을 사용하는 hash 기반으로 slot 16384로 구분
      - slot = crc16(key) % 16384
      - 레디스 서버 개수가 최대로 늘어나도 16384대를 넘어설 수 없음
    - key가 key{hashkey} 패턴이면 실제 crc16에 hashkey가 사용된다. (먼솔?)
    - 특정 redis 서버는 이 slot range를 가지고 있고, 데이터 migration은 이 slot 단위의 데이터를 다른 서버로 전달하게 된다. (migrateCommand 이용)
      - 관리자가 매뉴얼하게 사용하는 것
    - 클라이언트 - primary #1~3 - secondary #1~3
      - primary 죽으면 secondary가 primary가 된다.
      - primary끼리 슬롯 range 할당. (키를 분류한 것)
      - 요청 왔을 때 키가 자기 슬롯이면 ok하고 처리함. 다른 슬롯의 키가 오면 `-MOVED` 라는 에러를 내고 다른 슬롯으로 값을 보낸다. 라이브러리가 안해주면 에러 나는 것. 대부분의 라이브러리에서는 이 처리가 들어가 있는데, 직접 라이브러리 구현하면 빼먹을 수도 있다. 
      - 라이브러리에 의존성 있는 것이 레디스 클러스터
    - 장점
      - 자체적인 primary, secondary failover. 죽으면 자동으로 승격
      - slot 단위의 데이터 관리
    - 단점
      - 메모리 사용량이 더 많음
      - migration 자체는 관리자가 시점을 결정해야 함 (slot을 옮기기)
      - library 구현이 필요함 (많이 쓰지 않는 언어)

  ### Redis Failover

  1. Coordinator 기반 
     - zookeeper, etcd, consul 등의 coordinator를 사용한다.
     - <img width="608" alt="image" src="https://user-images.githubusercontent.com/41130448/169685029-d277770a-4418-4319-b6df-6430358ba70a.png">
     - 정보를 각각 저장 가능. 써야 하는 레디스 서버를 지정해주는 것 
       - 1번 레디스 죽으면 헬스 체커가 감지하고 2번을 P로 승격
       - 코디네이터에 업데이트 쳐줘서 2번을 사용하도록 지정
     - Coordinator 기반으로 설정 관리한다면 동일한 방식으로 관리 가능
     - 우리가 짜는 코드는 바꿀 수 있는데, 다른 솔루션은 바꿀 수 없음. 
  2. VIP/DNS 기반
     - <img width="649" alt="image" src="https://user-images.githubusercontent.com/41130448/169685093-7e37725e-2cc9-47f9-885b-160110698f61.png">
       - 가상 ip 하나 할당하고 거기로만 접속
       - P 서버 죽으면 헬스체커가 S를 P로 할당 시키고 VIP를 S로 할당한다.
       - 헬스 체커가 P에 있던 기존 커넥션 모두 끊어줘서 클라이언트가 재접속 하도록 유도한다. 
     - <img width="647" alt="image" src="https://user-images.githubusercontent.com/41130448/169685130-4e22f934-1d15-4bff-999e-2e482402bef1.png">
       - 위와 비슷하나 VIP 대신 DNS 할당
       - 코드 바꾸는 것이 아니므로 자동 failover
       - 잠시 끊어지는 것은 발생 가능
         - 복구 몇초, 몇십초 걸리고 매뉴얼한 작업 필요하지 않음
     - 클라이언트에 추가적인 구현이 필요 없음 
     - VIP vs DNS
       - VIP 기반은 외부로 서비스 제공해야 하는 서비스 업자에 유리함 (클라우드 업체 등)
         - VIP 바꾸면 무조건 바꾸어서 접속 
       - DNS 기반은 DNS cache TTL을 관리해야 함
         - 사용하는 언어별 DNS 캐싱 정책을 잘 알아야 함
           - 자바 같은 경우 default 30초 있고 이럼. 
         - 어떤 툴은 옵션에 따라서 한번 가져온 DNS 정보를 다시 호출하지 않는 경우도 있다.
           - DNS 바꿔도 원래꺼로 접속됨.
         - DNS 바꾸는게 훨씬 쉽다고 한당.
       - 아마존은 DNS, 다른 클라우드 업체는 VIP 쓰는 곳도 있다 
  3. Redis cluster의 사용
# 빅데이터 분산컴퓨팅

[KOCW 강의](http://www.kocw.net/home/cview.do?cid=34cda35d03934785)

## Apache Hadoop (1차시)

### 하둡이란?

- 빅데이터를 저장, 처리, 분석할 수 있는 소프트웨어 프레임워크

- 구글에서는 여러 SW를 오픈소스로 제공하지만 빅데이터 프레임워크는 공개하지 않았음

- 아파치에서 만든 오픈 소스 프로젝트

- 특징

  1. Distributed : 수십만 대의 컴퓨터에 자료 분산 저장 및 처리
  2. Scalable : 용량이 증대되는 대로 컴퓨터 추가
  3. Fault-tolerant : 하나 이상의 컴퓨터가 고장나는 경우에도 시스템이 정상 동작
  4. Open source : 공개 소프트웨어

- 하둡과 관련된 다양한 생태계가 존재한다.

  hive, pig, hbase 등등...

  하둡 시스템을 프로그래머가 아닌 일반 유저들이 사용하기 쉽도록 만든 것 (java, scala 대신 sql로 프로그래밍 할 수 있도록 - hive)

### 하둡을 왜쓰냐

- 기존 large-scale 컴퓨팅 시스템의 문제점을 해결하기 위한 방안임

- 구글과 같이 대용량 데이터 처리를 하는 응용 분야 출현

- 구글이 90말 - 00초 부터 대용량 데이터 웹페이지 처리 위해서 프레임워크 관리하는 방식 - 발표함

  storage (GFix, 구글 파일 시스템?) / computation (map-reduce 방식 MR)

  → Open하지 않음

  만들게 된 동기는 근처에 있던 싼 pc 수만대 모아서 IBM main Frame 성능 따라가도록 하기 위해서임

- 구글의 방식을 보고 똑같이 처리할 수 있도록 따라한게 하둡임

  야후에서 아파치 진영에 많이 가서 같이 만듦

- 기존에는 더 빠른 프로세서와 메모리를 이용해서 처리 

  → Distributed

### 분산 처리 시스템

- 더 많은 컴퓨터를 사용하자
- 분산 처리 시스템의 진화
  - 하나의 작업에 여러 대의 머신을 사용
  - MPI (Message Passing Interface) 메시지 패싱이 너무 복잡하다. 그래서 좀 쉽게 처리하는 방법 필요함

## 2차시

### 분산 처리 시스템 문제점 (하둡 이전)

- 프로그래밍이 복잡함. sync 유지 힘들어

- 수많음 컴퓨터 사용하는데, 일부가 고장나면 동작하지 않음 (Partial failure)

  컴포넌트에서 failure 일어나면 애플리케이션 성능을 저하시킨다.

  1. 시스템은 반드시 Partial failure에 대한 대처가 필요하다. 작업이 지속적으로 수행되고, 어떤 데이터의 손실도 발생하면 안된다.

  2. 시스템의 컴포넌트 fail이후 다시 recover된 경우 전체 시스템 재시작 없이 rejoin 하는 것이 가능해야한다.
  3. 컴포넌트의 failure는 job의 결과에 영향을 주면 안된다.

- 그렇다면 

  3개의 copy를 만들어서 나눠서 가지고 있자.

  서버에서는 메타 데이타 (데이터 복사본이 어디 있는지의 위치)를 가지고 있음. 그걸로 복구

- Scalability에 대해서

  1. 데이터의 양이 증가하면 → 각 작업의 성능이 감소, 시스템이 fail 되지 X (시스템이 뻗어버린다면 scalable한 것이 아님) 

     Software framework가 지원해줘야 함, PC를 붙힐수록 퍼포먼스가 증가함

  2. 시스템의 resource를 증가 → 비례적으로 로드 capacity가 증가함

### 하둡의 역사

- 90-00 구글 연구에서 시작 

  GFS in 2003 / MapReduce in 2004

- 기존 분산 컴퓨팅의 문제점(reliability, scalability)문제를 모두 해결할 수 있는 새로운 접근법이다.

  고장났을 때 / 데이터 커졌을 때의 해결책 존재

- 초기 데이터를 시스템에 분산하여 저장하는 것이 핵심적인 개념임

  클러스터에 있는 각 노드가 로컬 데이터에 대한 작업을 처리한다.

  초기 프로세싱을 위해 네트워크 데이터 전송이 이루어지지 않음

### 하둡의 핵심 컨셉트

- 가능하면 쉽게 설계하자. "Easy to use"가 철학임

  CS 하는 사람 말고 다른 사람들도 편하게 쓸 수 있도록

  애플리케이션을 고수준 코드로 작성함

  (네트워크, 의존성, 저수준 인프라 구조에 대해서 고려하지 않아도 됨)

- 각 노드들은 가급적 최소한의 데이터를 주고 받는다. "Shared nothing" architecture

  개발자는 노드들 사이에 일어나는 통신에 대한 코드 작성이 필요 없슴

- 여러 노드에 데이터 분산저장 

  availability, reliability위해서 여러 복제본 존재

### 하둡 대강 훑어보기

- 시스템이 데이터 로드할 때 **블락**이라는 단위로 나눈다. (Storage)

  기본적으로 한 블락은 64MB or 128MB

- 계산은 **Map reduce** 방식을 사용한다. (Computation)

  (Map이라는 작업과 Reduce라는 작업이 있음 → Map task, reduce task 돌아가면서 일어남)

  Map tasks는 블락 하나 단위의 작업을 처리한다. 

- 분산되어 저장된 데이터 블락에 대해서 Map task 작업을 각 노드에 할당한다. 병렬적으로 작업 수행함.

### Fault Tolerance

- Node는 1대의 pc를 의미함 (CPU와 메모리를 가지고 있음)

- 노드 하나가 fail한 경우 마스터 노드가 감지하고 작업을 다른 노드에 할당한다. 

- Task를 재시작 하기 위해 다른 작업하던 다른 노드와의 통신이 필요하지 않음

  fail된 노드 재시작시 자동으로 시스템에 연결되고 새로운 task를 할당 받는다.

- 특정 노드가 성능이 낮다고 감지되면, 마스터 노드는 그 노드가 하던 같은 task를 다른 노드에 할당한다.

  → Speculative Execution

## 3차시

### 하둡 설치 및 실행


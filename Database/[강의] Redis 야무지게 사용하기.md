# Redis 야무지게 사용하기

Ref : [[NHN FORWARD 2021\] Redis 야무지게 사용하기 - YouTube]](https://www.youtube.com/watch?v=92NizoBL4uA)



## Redis 캐시로 사용하기

- 캐시란
  - 사용자 입장에서 원래 **데이터 소스보다 빠르고** 효율적으로 액세스
  - 임시 데이터 저장소
  - 동일한 데이터에 반복적으로 접근할 때 (데이터 재사용 횟수)
- 단순한 구조 
  - 캐시로 쓰기 좋음
  - 키밸류 구조
  - 모든 데이터를 메모리에 올린다 (그래서 빠름)
  - 평균 작업 속도 1ms 보다 적음
- 캐싱 전략
  - 데이터의 유형과 데이터 액세스 패턴을 잘 고려해서 선택해야 함
  - 읽기 전략
    - Look aside (lazy loading)
      - 가장 일반적으로 사용하는 전략임
      - 어플리케이션은 데이터를 찾을 때 캐시 먼저 확인
      - 캐시에 데이터 있으면 가져오고 없으면 디비에 직접 접근 후 레디스에 올림
      - 레디스 다운되더라도 장애로 이어지지 않고, 디비에서 가져옴
      - 캐시로 붙어 있던 커넥션 많았다면 그 커넥션이 모두 디비로 붙으므로 디비에 부하가 많이 몰릴 수 있음
      - 캐시 새로 투입하고나 디비에만 새로운 데이터 저장했다면 처음에 캐시 미스 많이 발생
        - 이 때는 디비에서 캐시로 데이터 밀어넣는 cache warming 진행
  - 쓰기 전략
    - Write around
      - 디비에만 모든 데이터 저장
      - 캐시 미스 발생하면 캐시에서 데이터 끌어옴
      - 캐시 != 디비 데이터 다를 수 있음
    - Write through
      - 디비 데이터 저장할 때 캐시에도 함께 저장
      - 캐시는 항상 최신 정보 가지고 있을 수 있음
      - 저장할 때마다 두 단계의 스텝 거쳐야 함 
        - 상대적으로 느림
      - 저장하는 데이터 재사용 되지 않을 수 있는데, 무조건 캐시에 올리므로 리소스 낭비일 수도
        - exp time 설정해주는게 좋음 
        - 값의 관리를 어떻게 하는가 -> 장애 포인트가 될 수 있음

## Redis 데이터 타입 야무지게 활용하기

- 자체적으로 많은 자료 구조 제공중
  - 특정 상황에서 어떻게 효율적으로 사용할 수 있을까?
- 제공하는 데이터 타입
  - String
    - set cmd 쓰면 다 string으로 들어감
  - bitmap
    - string의 변형이라고 볼수도 있음 
    - 비트 단위의 연산 가능
    - 데이터 저장공간 절약
    - 정수로 된 데이터만 카운팅 가능 
  - List
    - 데이터 순서대로 저장 
    - 큐로 사용하기 적절
  - Hash
    - 하나의 키 안에 여러 개의 필드 (키밸류 쌍)
  - Set
    - 중복되지 않는 문자열 
  - Sorted set
    - 중복되지 않는 값 저장하지만
    - 모든 값이 score라는 숫자값으로 정렬됨
    - 데이터 저장될 때부터 스코어로 정렬
    - 스코어 같으면 사전순으로 정렬
  - HyperLogLogs
    - 굉장히 많은 데이터 다룰때 쓴다
    - 중복되지 않는 값의 개수를 count할 때 쓴다. 
  - Streams
    - 로그를 저장하기 좋음
- Counting 상황
  - String 
    - 무난한 상황
    - 키 하나를 만들어서 상황마다 증감
    - INCR, INCRBY, INCRBYFLOAT, HINCRBY, HINCRBYFLOAT, ZINCBY
  - Bitmap
    - 1천만명 유저 -> 1천만 비트로 카운팅
      - 1.5MB밖에 안됨 (정수형 유저 아이디에 해당하는 위치를 set)
      - 비트카운트 연산으로 1로 설정된 개수 셀 수 있음
    - id가 sequential한 정수형이어야 함
  - HyperLogLogs
    - 데용량 데이터를 카운팅 할 때 적절 (오차 0.81%)
      - 모든 string data를 unique하게 구분할 수 있음
    - set과 비슷하지만 저장되는 용량은 매우 작음 (12KB 고정)
    - 저장된 데이터는 다시 확인할 수 없음 (??) 
      - 경우에 따라 데이터를 보호하기 위한 목적으로도 쓸 수 있음 
    - 웹사이트 방문한 ip가 몇개가 되는지, 트롤링한 url의 개수, 검색 엔진에서 검색한 유니크한 검색어
    - PFADD, PFCOUNT, PFMERGE
    - 일별 데이터 -> 일주일 (PFMERGE)
- 메세징 상황
  - Lists
    - 메세지 큐로 사용하기 적절
    - Blocking 기능 -> 불필요한 polling 프로세스 막을 수 있음 
    - BRPOP
    - LPUSHX, RPUSHX
      - 키가 있을 때만 데이터 저장 가능
        - 키가 이미 있다는건 예전에 사용되었던 큐라는 뜻 
        - 비효율적인 데이터 이동을 막을 수 있음 
      - 트위터 타임라인에 트윗 캐싱
        - 이미 캐싱되어 있는 피드에만 신규 트윗을 저장
        - 트위터 자주 이용하는 유저에게만 새로운 트윗을 캐시
        - 자주 사용하지 않는 유저는 해싱 키 자체가 존재하지 않음 
          - 데이터 미리 쌓는 비효율적인 작업 안하기
  - Streams
    - 로그를 저장하기 가장 적절한 자료구조
    - append only
    - 중간에 데이터 바뀌지 않음
    - 검색
      - 시간 범위로 검색, 신규 추가 데이터 수신(tail같은것), 소비자별 다른 데이터 수신 (카프카처럼 소비자 개념 존재)
      - 메세징 브로커가 필요할 때 카프카 대체해서 간단하게 쓸 수 있는 자료구조
    - XADD
      - id 위치에 * 를 넣으면 알아서 id 만들고 반환함

## Redis에서 데이터를 영구 저장하려면? (RDB vs AOF)

- 인메모리

  - 서버 재시작시 모든 데이터 유실
  - 복제 기능 사용해도 사람의 실수 발생시 데이터 복원 불가
  - 캐시 이외의 용도로 사용한다면 적절한 데이터 백업 필요

- 영구 저장 옵션

  - aof (append only file)
    - 데이터 변경하는 커맨드 들어오면 그대로 저장
    - 크기가 커짐 (주기적으로 압축해서 재작성하는 과정 거쳐야 함)
    - 레디스 프로토콜 형태로 저장
    - 자동/수동
      - 자동 : redis.conf에서 `auto-aof-rewrite-percentage` 옵션 (크기 기준)
      - 수동 : `BGREWRITEAOF` 커맨드 이용, CLI 창에서 수동으로 AOF 파일 재작성
  - RDB
    - snapshot 방식으로 동작
    - 저장 당시의 데이터를 사진찍듯이 저장, 파일로 저장
    - binary 파일 형태로 저장
    - 자동/수동
      - 자동 : redis.conf 파일에서 `SAVE` 옵션 (시간 기준)
      - 수동 : `BGSAVE` 커맨드 이용해서 CLI 창에서 수동으로 RDB 파일 저장
        - `SAVE` 커맨드는 절대 사용 ㄴㄴ

- 선택 기준

  - 캐시로만 사용하면 저장 굳이 안해도 됨

  - 백업은 필요하지만 어느 정도의 데이터 손실이 발생해도 괜찮은 경우

    - RDB 단독 사용

    - redis.conf 파일에서 SAVE 옵션을 적절히 사용

      - `SAVE 900 1`

        900초동안 1개 이상의 키가 변경되었을 때 RDB 파일을 재작성

  - 장애 상황 직전까지의 모든 데이터가 보장되어야 할 경우

    - AOF 사용 (`appendonly yes`)
    - `APPENDFSYNC` 옵션이 `everysec`인 경우 최대 1초 사이의 데이터 유실 기능 (기본 설정)

  - 제일 강력한 내구성이 필요한 경우

    - RDB & AOF 동시 사용

## Redis 아키텍처 선택 노하우 (Replication vs Sentinel vs Cluster)

- Replication 구성

  - 마스터와 리플리카만 존재
  - 단순히 복제만 연결된 상태
    - 복제는 모두 비동기식으로 동작
      - 마스터에서 복제본의 데이터가 잘 전달되었는지 매번 확인하고 기다리지는 않음 
    - `replicaof` 커맨드를 이용해 간단하게 복제 연결
    - HA 기능이 없으므로 마스터에 장애 상황 시 수동으로 복구해야 할 작업이 많음 
      - 리플리카 노드에 직접 접속해서 복제 끊어야 함 
      - `replicaof no one`
      - 애플리케이션에서 연결 정보 변경 해야 해서 배포해야 하는 작업 필요함 

- Sentinel 구성

  - 마스터와 리플리카 외에 센티널 노드 필요
  - 센티널 : 일반 노드를 모니터링 하는 역할
    - 자동 페일오버 가능한 HA 구성
    - 마스터가 비정상 상태일 때 자동으로 페일 오버
      - 기존의 리플리카가 자동으로 마스터가 됨 
      - 어플리케이션에서 연결 정보 필요 없음
      - 어플리케이션에서는 센티널 노드만 알고 있으면 됨 
      - 센티널이 변경된 마스터 정보로 바로 연결해줌
    - 센티널 프로세스 따로 띄워야 함, 항상 3대 이상의 홀수로 존재해야 함
    - 과반수 이상의 센티널이 동의해야 페일오버 진행 

- Cluster 구성

  - 최소 3대의 마스터 필요
    - 리플리카 노드를 하나씩 추가하는게 일반적인 구성 
  - 모든 노드가 서로를 감시하며, 마스터 비정상 상태일 때 자동 페일오버 
  - 샤딩 기능 제공
    - 키를 여러 노드에 자동으로 분할해서 저장 

- 아키텍처 선택 기준

  - HA 필요? (자동 failover)
    - ㅇㅇ
      - 샤딩 필요? 
        - ㅇㅇ : Cluster
        - ㄴㄴ : Sentinel
    - ㄴㄴ
      - 복제 기능 필요?
        - ㅇㅇ : Replication
        - ㄴㄴ : Stand-Alone

  

## Redis 운영 꿀팁 + 장애 포인트 


# 대규모 서비스를 지탱하는 기술

이토 나오야, 다나카 신지 공저 / 진명조 옮김 

## 1. 대규모 웹 서비스 개발 오리엔테이션 - 전체 그림 파악하기

<br>

### 0강. 이 책의 근간

#### 이 책에서 알아가는 것

- 대규모 서비스, 데이터를 다룰 경우를 대비한 기본적인 사고방식, 개념, 개요
- How-to 습득이 아닌 밑바탕이 되는 전체 그림을 파악

<br>

### 1강. 대규모 서비스와 소규모 서비스

#### 하테나의 서비스 규모

- 등록 사용자는 100만명 이상, 1,500만 UU(unique user)/월
- 수십 억 액세스/월
- 피크 시 회선 트래픽 양은 430Mbps
- 서버는 500대 이상

#### 소규모/대규모 서비스의 차이

1. 확장성 확보, 부하분산 필요

   액세스가 많으면 서버 1대로 처리 불가 -> 스케일 아웃 전략 사용

   하드웨어의 성능과 가격은 비례하지 않으므로 스케일 아웃이 비용 측면에서 좋다.

   하지만 스케일 아웃을 하면 새로운 문제가 발생한다. 

   - 사용자의 요청을 분배할 로드밸런서가 필요하다
   - 데이터 동기화가 필요하다

   - 네트워크 통신의 지연시간을 고려해야 한다. (통신의 오버헤드 존재)

2. 다중성 확보

   특정 서버에 문제가 생기더라도 계속 서비스를 제공할 수 있어야 한다. 이를 다중성을 지녔다고 한다.

   스케일 아웃을 하면 서버 대수가 늘어나고, 이는 서버의 고장률이 증가한다는 것을 의미한다.

   웹 서비스는 언제 어떤 경우든 고장에 대해 견고해야 한다. 

   > 야후는 미국의 테러 발생 시 다량의 검색으로 Top 페이지가 다운되었음. 이 때 CDN 서비스에 컨텐츠를 캐싱해서 트래픽을 우회해서 복구함

   시스템이 고장나면 그걸로 끝이어도 괜찮은 시스템 구축과, **고장 나더라도 다른 시스템이 자동적으로 처리를 인계받는 시스템** 구축 간에는 기술적/비용적 차이가 상당하다.

3. 효율적 운용 필요

   서버 대수가 100대를 넘으면 각 서버의 역할과 상황 파악이 힘들다. 

   이들을 효율적으로 운용하기 위해 자동화가 필요하다.

4. 개발자 수, 개발 방법의 변화

   서비스가 커지면 여러 기술자가 역할을 분담해서 일한다. 이 경우에도 개발 표준화와 관련된 새로운 문제가 발생한다.

   예를 들면 프로그래밍 언어, 라이브러리, 프레임워크, 코딩 규약, 버전관리 시스템의 사용 등이 있다.

   표준화의 틀을 정하는 것뿐만 아니라, 전체를 조정할 역할이 필요하다. 표준화 규칙이 지켜지고 있는지, 능력 차이에 발생하는 비효율 조정과 팀원 교육 등이 필요하다.

#### 하지만 가장 중요하게 다룰 것

데이터량이 커진다는 것을 가장 중요하게 다를 것이다.

- 컴퓨터가 처리를 수행하는 과정

  1. 디스크에서 데이터를 로드

  2. 메모리에 저장

  3. 저장된 메모리 데이터를 CPU가 fetch함

     이 과정에서 캐시 메모리에 캐싱

  4. CPU가 특정 처리를 수행

- 여기서 각 단계 사이에서는 속도차가 크게 발생한다.

  속도차에 대한 비효율을 줄이기 위해 데이터를 캐싱한다.DB 등의 미들웨어에서도 속도차를 줄이기 위해 데이터 구조와 구현을 맞추고 있다. 

- 하지만 한계가 있다. 데이터량이 많아지면 캐시미스 발생이 많아진다. 그러면 결국 디스크 I/O가 많아져 시스템 전체의 속도 저하를 일으킨다. 

  데이터가 적을 때에는 특별히 고민하지 않아도 모두 메모리에서 처리할 수 있다. 또한 간단한 알고리즘을 사용하는 것이 오버헤드가 적으므로 I/O 부하도 문제되지 않는다.

  하지만 서비스가 어느 정도 규모를 넘어서면 응급 처치로 문제가 해결되지 않는다.

- 그래서 대규모 서비스에서는

  1. 어떻게 하면 데이터를 적게 가져갈 수 있을까
  2. 여러 서버로 분산시킬 수 있을까
  3. 필요한 데이터를 최소한의 횟수로 읽어들일 수 있을까

  등등을 본질적으로 고민해야 한다.

<br>

### 2강. 계속 성장하는 서비스와 대규모화의 벽

- 서비스가 계속 성장하면서 보유하는 데이터량과 트래픽이 커진다.

  이에 따라 시스템 확장이 필요하게 된다.

#### 하테나가 성장하면서

1. 시행착오를 거듭한 시스템 규모 확장

   - 다중화와 부하 분산을 적용하려 했지만, 당시 상용 로드 밸런서는 매우 고가여서 사용할 수 없음

     따라서 오픈소스를 활용하였다 : Linux 박스로 라우터 구축, 아파치의 `mod_rewrite` 를 통해 HTTP 요청을 분산, MySQL의 레플리케이션

   - 하지만 블로그 붐이 일어나면서 시스템이 트래픽을 못따라감

2. 데이터 센터로의 이전, 시스템 쇄신

   - 서버 룸에서 인터넷 데이터 센터로 서버 이전을 시작했다.

     이전 작업을 하면서 네트워크 설계를 근본적으로 재수정하고, 낡은 서버를 교체하기로 함

   1. 기존 시스템의 부하 상황을 정리
      - 서비스 구성 중에 병목 지점을 측정 및 판정
      - I/O 부하가 높은 서버는 메모리를 중요시 / CPU 부하가 높은 서버는 CPU를 중요시 하는 형태로 용도에 맞는 하드웨어 구성

   2. 다중화는 오픈소스 LVS + keepalived 도입

      로드 밸런서 + 가동감시 기능

   3. Linux 박스로 구축한 로드 밸런서를 여러 부분에 도입

   4. OS를 가상화 하여 서버 가동률과 유지보수성 높임

   5. 서버 정보관리 시스템 개발

      서버의 용도, 부하 상태 등의 정보에 액세스하여 시스템 전체를 파악

   6. 애플리케이션의 각종 로직, DB 스키마 재검토 -> 비효율적인 부분 배제

#### 시스템의 성장 전략

- 서비스가 소규모라면 간단한 구조가 오히려 더 나을 수 있다. 

  너무 최적화를 이르게 시작하는것이 최선은 아닐 수 있음, 비용 문제도 존재

- I/O 부하 상승과 같은 대규모화의 벽은 갑자기 발생한다. 

  캐시 미스 발생후 갑자기 문제가 복잡해지기 때문에, 알아차렸을 때에는 이미 시스템이 저속화되어 있을 수 있다.

  이를 예방하기 위해 어느 정도의 수용능력 관리와 서비스 설계 시 필요 이상으로 데이터를 증가시키지 않도록 신경써야 함

<br>

### 3강. 서비스 개발의 현장

#### 하테나의 기술팀 체제

1. 서비스 개발부
   - 서비스 구현을 담당. 애플리케이션 측면의 개선
   - 담당하는 서비스의 성능을 트래킹
   - 주요한 페이지가 어느 정도의 응답시간에 응답하고 있는지 정량화하고 지표삼아 개선
2. 인프라부
   - 서버/인프라 시스템의 운용을 담당
   - 서버 준비, 데이터 센터 운용, 부하 분산
   - 고장, 과부하, 설정 미비, 노후화로 인한 교체

<br>

## 2. 대규모 데이터 처리 입문 - 메모리와 디스크, 웹 애플리케이션과 부하

- 대규모 데이터란 무엇인가, 어느 정도인가?
- 소량의 데이터 처리와 무엇이 다른가?

### 4강. 하테나 북마크의 데이터 규모

- 데이터 규모 (2009.08)

  | 레코드 수                 | 데이터 크기                         |
  | ------------------------- | ----------------------------------- |
  | entry 테이블 : 1,520만    | 3GB                                 |
  | bookmark 테이블 : 4,500만 | 5.5GB                               |
  | tag 테이블 : 5,000만      | 태그 : 4.8GB<br />HTML : 200GB 이상 |

- 기가 바이트 단위의 테이블 정도가 중~대규모라고 하는 듯

  구글이나 야후로 가면 테라/페타바이트 이상의 초대규모가 된다. (지금은 훨ㄹㄹㄹㄹㄹㄹ씬 더 크겠지)

- 수천만 건의 레코드, 수~수백GB의 데이터

  이 정도 규모의 DB에 쿼리를 던지면 결과가 나오는 시간이 다르다. 인덱스를 태우지 않고 쿼리를 던지면 한번 검색하는 데에 몇백초가 걸릴 수 있다.

### 5강. 대규모 데이터 처리의 어려운 점

#### 뭐가 어려운가? : 메모리 내에서 계산할 수 없다.

- 너무 커서 메모리에 다 올릴 수 없으므로 디스크를 계속 읽으면서 검색해야 한다. 디스크를 읽는 것이 문제가 된다.

  만약 메모리 내에서 다 계산할 수 있으면 아무리 무식하게 계산하더라도 몇백초나 기다리지는 않을 것임.

- 메모리와 디스크의 속도차는 10만~100만배 이상이다. (10^5 ~ 10^6)

#### 디스크는 왜 늦을까?

1. 디스크는 원반이 회전하고 있으며 물리적으로 이동하며 탐색하므로 느림.
   - 헤드가 원하는 위치로 이동해서 데이터를 읽어내야 함. 만약 원하는 위치가 헤드보다 조금 앞에 가버리면 한바퀴 더돌려야 함
   - 이분 탐색과 같이 여기저기 찾아야 하는 알고리즘을 사용한다면, 계속 회전하면서 헤드를 이동해야 하므로 물리적인 오버헤드가 커진다.
   - OS는 이걸 어느정도 커버하기 위해서 연속된 데이터를 같은 위치에 쌓고 한꺼번에 (4KB 정도)를 읽는다. 이를 통해 디스크의 회전 횟수를 최소화 하려고 한다.

2. 버스의 전송 속도도 차이가 난다.

   - 메모리 - CPU는 빠른 버스로 연결되어 있음 (7.5GB/초)

     디스크 - 메모리는 버스 속도가 훨씬 느림(58MB/초) 100배 정도 느림

     `hdparm` 사용해서 측정 가능

   - SSD는 물리적으로 회전하지 않으므로 탐색은 빠르지만 버스 속도가 병목이 될 수 있다. 아무튼 메모리정도 속도는 안나온다.

#### Linux 단일 호스트의 부하

- 한 대에서 처리할 수 있는 부하를 10대로 분산하는 것은 본말이 전도된 것임

  단일 서버의 성능을 충분히 끌어낼 수 있는 것을 전제로 부하 분산을 해야 의미가 있다.

- 추측하지 말고 계측해라

  단일 호스트의 성능을 끌어내기 위해서는 서버 리소스의 이용 현황을 정확히 파악해야 한다.

  계측을 통해 시스템의 병목을 규명하고, 집중적으로 제거하여 성능을 향상시킬 수 있다.

#### 병목 규명작업의 기본적인 흐름

1. Load average 확인

   - `top` 이나 `uptime` 등의 명령을 통해 평균적인 로드를 확인한다. 이는 시스템 전체의 부하 상황을 나타내는 지표가 될 수 있다.

     하지만 이 값으로는 병목의 원인을 판단할 수 없고, 이 값을 시초로 해서 조사를 시작한다.

   - Load average는 낮은데 시스템의 전송량이 오르지 않을 경우도 있다. 이 때에는 소프트웨어의 설정이나 오류, 네트워크, 원격 호스트 측이 원인이 될 수 있다.

2. CPU, I/O 병목 원인 조사

   - Load average가 높은 경우 어느 쪽이 원인인지 조사한다.
   - 시간 경과에 따라 CPU 사용률이나 I/O 대기율의 추이를 확인한다.

#### CPU 부하가 높은 경우

- 사용자 프로그램의 처리가 병목인지, 시스템 프로그램이 원인인지 확인한다. `top` 이나 `sar` 등을 통해 확인한다.
- `ps` 로 볼 수 있는 프로세스의 상태나 CPU 사용 시간 등을 보면서 원인이 되는 프로세스를 찾는다.
- 프로세스를 찾은 후 `strace` 로 추적하거나, `oprofile` 로 프로파일링을 하여 병목 지점을 좁힌다.

- 보통 CPU 부하는 둘 중 하나이다.

  1. 디스크나 메모리 용량 등 그 밖의 부분에서는 병목이 되지 않는, 이상적인 상태

     시스템 전송량에 문제가 있다면 서버를 증설하거나 프로그램 로직/알고리즘을 개선한다.

  2. 프로그램이 폭주해서 CPU에 필요 이상의 부하가 걸리는 경우

     오류를 제거해서 프로그램이 폭주하지 않도록 대처한다.

#### I/O 부하가 높은 경우

보통 프로그램으로부터 입출력이 많아서 부하가 높거나, 스왑이 발생해서 디스크 액세스가 발생하는 상황이 대부분이다.

`sar`, `vmstat` 등으로 스왑의 발생상황을 확인해서 문제를 가린다. 

1. 스왑이 발생하는 경우 다음과 같은 조사를 해본다.

   - 특정 프로세스가 극단적으로 메모리를 소비하고 있는지 `ps` 를 통해 확인한다.
   - 프로그램의 오류로 메로리를 지나치게 사용하는 경우 프로그램을 개선한다.
   - 탑재된 메모리가 부족한 경우에는 메모리를 증설한다. 증설할 수 없으면 분산을 검토한다.

2. 스왑이 발생하지 않고, 디스크 입출력이 빈번하게 발생하는 경우 캐시에 필요한 메모리가 부족한 것일 수 있다.

   - 메모리 증설로 캐시 영역을 확대시킬 수 있는 경우 메모리를 증설한다.

   - 메모리 증설로 대응할 수 없다면, 데이터 분산이나 캐시서버 도입 등을 검토한다.

     프로그램을 개선해서 I/O 빈도를 줄이는 것도 검토한다.

#### OS 튜닝이란 : 부하의 원인을 알고 / 제거하는 것

- 병목이 발견되면 이를 제거하는 작업이 본래 의미임

- 본래 하드웨어나 소프트웨어가 지닌 성능 이상을 내는건 불가능하다.

  본래 지닌 성능을 충분히 발휘할 수 있도록 문제가 되는 부분을 제거하는 것이 본질이다.

- 원인을 알면 해당 원인에 대한 대응 방법은 자명하다.

<br>

### 6강. 규모조정의 요소

- 앞에서는 메모리와 디스크의 속도차에 대해 다뤘음. 데이터가 커지면 이 속도차가 문제를 야기한다.

- 웹 서비스의 성능 향상은 스케일업과 스케일 아웃이 있다.

  스케일 아웃 전략이 웹 서비스에 적합한 형태이고, 비용이 저렴하며, 시스템 구성에 유연성이 있으므로 더 나은 전략이다.

- 하드웨어 가격은 성능과 비례하지 않는다. 동일한 성능을 확보하기 위해서 저가의 하드웨어를 나열해 확보하는 게 더 나을 수 있다.

- 시스템 구성이 유연하다는 것 : 부하가 적을 때에는 최소한으로 투자, 부하가 높아지면서 확장하기 용이하며 빠르게 상황 대처 가능

#### 규모 조정의 요소 - CPU 부하와 I/O 부하

- 스케일 아웃을 통해 CPU 부하의 확장성 확보는 쉽다.

  프록시/AP 서버가 담당하며, 동일한 서버의 대수만 늘리면 된다. 로드 밸런서로 요청을 균등하게 분산해준다.

- DB 서버에는 I/O 부하가 걸린다. 데이터를 분산하는 경우 동기화에 대한 문제가 발생한다.

  1. 쓰기는 간단하게 분산할 수 없다.

  2. 또한 디스크 I/O가 많이 발생하면 이 때문에 서버도 함께 느려질 수 있다.

- 같은 서버라도 부하의 종류가 다르면 특성이 크게 달라진다.

  CPU-bound / I/O bound program

#### 멀티태스킹 OS와 부하

- 멀티 태스킹은 짧은 시간 간격으로 여러 태스크를 전환하며 실현된다.

- 실행할 태스크가 적은 상황에서는 태스크에 대기를 발생하지 않고 전환할 수 있다.

  실행할 태스크가 늘어나면 특정 태스크 A가 CPU에서 계산을 수행하고 있는 동안 다른 태스크 B나 C가 CPU를 사용하기 위해 대기해야 한다.

  대기 상태는 프로그램의 실행 지연으로 나타난다.

- `top` 를 출력시키면 Load average를 확인할 수 있다. 

  ```
  load average: 0.70, 0.66, 0.59
  ```

  왼쪽부터 차례로 1, 5, 15분 동안에 단위 시간당 대기된 태스크의 수를 나타낸다. 

  이 값들이 높다면 그만큼 작업 실행에 대기가 발생한다는 뜻이므로 지연이 되는, 즉 부하가 높은 상황이라고 할 수 있다.

#### Average가 보고하는 부하의 정체

- 하드웨어는 일정 주기로 CPU에 인터럽트 신호를 보낸다.

  이는 타이머 인터럽트인데, 이게 걸릴 때마다 CPU는 실행중인 프로세스가 CPU를 얼마나 사용했는지 계산하는 등 시간에 관련된 처리를 수행한다.이 때 load average도 계산된다.

  > Centos에서는 4ms 간격으로 보낸다.

- Load average는 타이머 인터럽트가 발생했을 때, 실행 가능 상태인 태스크와 I/O 대기중인 태스크를 개수를 단위 시간으로 나눈 것이다.

  즉, 처리를 실행하려고 해도 실행할 수 없어서 대기하고 있는 프로세스의 수이다.

  구체적으로는

  - CPU의 실행 권한이 부여되기를 기다리고 있는 프로세스
  - 디스크 I/O가 완료하기를 기다리고 있는 프로세스

- Load average 자체는 두 가지의 부하를 합친 수치이므로, 어느 부분의 부하가 높은지는 판단할 수 없다.

<br>

### 7강. 대규모 데이터를 다루기 위한 기초지식



## 3. OS 캐시와 분산 - 대규모 데이터를 효율적으로 처리하는 원리

## 4. DB 스케일아웃 전략 - 분산을 고려한 MySQL 운용

## 5. 대규모 데이터 처리 실전 입문 - 애플리케이션 개발의 급소

## 6. [과제] 압축 프로그래밍 - 데이터 크기, I/O 고속화와의 관계 인식하기

## 7. 알고리즘 실용화 - 가까운 예로 보는 이론, 연구의 실전 투입

## 8. [과제] 하테나 키워드 링크 구현 - 응용으로 가는 길 깨닫기

## 9. 전문 검색기술 도전 - 대규모 데이터 처리의 노하우

## 10. [과제] 전문 검색엔진 작성 - 기초, 상세부분 작성, 속도와 정확성 추구

## 11. 대규모 데이터 처리를 지탱하는 서버/인프라 입문 - 웹서비스의 백엔드

## 12. 확장성 확보에 필요한 하고 방식 - 규모 증대와 시스템 확장

## 13. 다중성 확보, 시스템 안정화 - 100%에 근접한 가동률을 실현하는 원리

## 14. 효율향상 전략 - 하드웨어의 리소스 사용률 높이기

## 15. 웹 서비스와 네트워크 - 서비스의 성장

## Appendix A. 현대 웹 서비스 구축에 필요한 실전 기술 - 대규모 서비스에 대응하기 위해서

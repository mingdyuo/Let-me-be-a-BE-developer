# 데이터 중심 애플리케이션 설계

<br>

애플리케이션 개발 과정의 변화

- CPU 클럭 속도는 거의 증가하지 않고 있음. 멀티코어  프로세서가 표준이 되었고 네트워크는 빨라지고 있음. 이와 함께 병렬 처리가 늘어나고 있다.
- IaaS 덕분에 쉽게 분산 시스템 개발 및 다양한 지역에 구축 가능
- 사람들은 서비스 제공에 더 높은 기준을 요구함. 서비스 중단 시간을 용납하지 못함

애플리케이션을 두 가지로 나누어 볼 수 있다.

1. 데이터 중심 애플리케이션

   데이터가 주요 challenging한 요소인 경우

2. 계산 중심 애플리케이션

   CPU 사이클이 병목인 경우

<br>

## 1장 데이터 시스템의 기초

## 01 *신뢰*할 수 있고 *확장 가능*하며 *유지보수*하기 쉬운 애플리케이션

- 오늘날 많은 애플리케이션은 데이터 중심적임. 문제가 되는 요소는 데이터의 양, 복잡도, 변화 속도이다.
- 애플리케이션이 필요로 하는 것 : 데이터베이스, 캐시, 검색 색인, 스트림 처리, 일괄 처리
- 애플리케이션마다 요구사항이 다르므로 DB 시스템도 다양한 특성이 있다.
- 신뢰성, 확장성, 유지보수성의 의미를 명확히 하자. 그리고 이를 고려하는 방법을 알아보자.

<br>

### 데이터 시스템에 대한 생각

- 데이터베이스, 큐, 캐시 등은 서로 다른 성능과 특징을 가지고 있지만 데이터 시스템이라는 이름으로 퉁치는 이유

  1. 새로 생긴 툴들은 전통적인 분류에 잘 맞지 않음, 분류 간 경계가 흐림

     예) 레디스(메시지 큐로 사용하는 데이터스토어), 아파치 카프카(지속성을 보장하는 메시지 큐)

  2. 많은 애플리케이션들의 요구사항이 넓고 깊어짐. 데이터 처리와 저장을 모두 만족시킬 수 없음. 작업을 태스크로 나누고, 애플리케이션 코드를 이용해 연결한다.

     예) 인메모리 캐시, 전문 검색 서버 등을 따로 사용하며 동기화 유지

  → 개발자는 이제 애플리케이션 설계 뿐만 아니라 데이터 시스템도 함께 설계 해야 함

- 신뢰성, 확장성, 유지보수성 중심으로 살펴볼 것이다. 용어의 의미를 명확히 이해하고 엔지니어링 관점에서 생각해보자.

<br>

### 신뢰성

- 하드웨어, 소프트웨어 결함, 인적 오류에도 시스템이 **원하는 성능 수준에서 지속적으로 올바르게 동작**하는 것

- 결함과 장애는 동일하지 않다. 장애는 시스템 전체가 멈추어 사용자에게 서비스를 제공하지 못하는것

  결함으로 인해 장애가 일어나지 않도록 설계하는 것이 좋다.

- 고의적으로 결함을 유도해서 시스템이 잘 대처하도록 훈련할 수도 있다. (넷플릭스의 카오스 몽키)

  > 1. 시스템의 “정상 상태”를 정의해 정상 동작의 기준선을 설정한다.
  >
  > 2. 대조군과 실험군 양쪽에서 모두 이 정상 상태가 계속된다는 가설을 세운다.
  >
  > 3. 서버 멈춤, 하드 드라이브 고장, 네트워크 연결 끊김과 같은 실제 상황을 반영하는 변수를 도입한다.
  >
  > 4. 대조군과 실험군 사이의 차이점을 확인해 가설이 틀렸음을 입증한다.

- 보안 문제에서는 결함을 예방하는 것이 매우 중요하다. 

- 해결책을 마련할 수 있는 결함 유형을 다뤄보자.

<br>

1. 하드웨어 결함
   - 하드웨어의 결함은 대체로 무작위적으로 독립적이다. 온도와 같은 약한 상관관계가 있을 수는 있지만 보통 여러 구성 요소에서 동시 다발적으로 장애가 생기지는 않는다.
   
   - 하드디스크에서 장애가 발생하는 평균 시간은 10~50년이다. 10,000개의 디스크로 구성된 저장 클러스터라면 평균적으로 하루에 하나의 디스크가 죽는다고 생각하면 된다.
   
   - 대응 방법은 각 하드웨어 구성 요소에 중복을 추가하는것
   
     > 이중 전원 디바이스, hot-swap이 가능한 CPU, 예비 디젤 발전기 갖추기 등
   
   - 데이터 양과 계산 요구가 늘면서 더 많은 장비가 사용된다. 이에 비례해서 하드웨어 결함률도 증가함
   
     AWS같은 클라우드 플랫폼은 별도의 경고 없이 가상 인스턴스가 사용 불가상태가 된다. 
   
     > 애초에 설계할 때 단일 장비 신뢰성보다 유연성, 탄력성을 우선적으로 처리하게끔 되어 있음
   
   - 암튼 소프트웨어 내결함성 기술 + 하드웨어 중복성으로 전체 장비의 손실을 견딜수 있게 시스템화 하고 있다.
   
     한번에 한 노드씩 패치하여 업그레이드할 수도 있다.
   
2. 소프트웨어 오류

   - 시스템 내의 체계적 오류 같은 것이다. 

   - 특정 상황에 의해 발생하기 전까지 오래 나타나지 않으므로 예상하기 어렵다.

     노드 간의 상관관계 떄문에 (서로 독립적인) 하드웨어보다 시스템 오류를 더욱 많이 유발하는 경향이 있다.

     > 예시
     >
     > - 잘못된 특정 입력 시 모든 서버 인스턴스가 죽는 버그. 리눅스 커널의 2012.06.30 윤초 오류
     > - CPU, 메모리, 디스크, 네트워크 대역폭처럼 공유 자원을 과도하게 사용하는 일부 프로세스
     > - 시스템의 속도가 느려져 반응이 없거나 잘못된 응답을 반환하는 서비스
     > - 연쇄 장애 (cascading failure)

   - 신속한 해결책이 없다. 다음과 같은 것들로 최대한 예방 해야 한다.

     → 시스템의 가정과 상호작용에 대해 주의 깊게 생각, 빈틈없는 테스트, 프로세스 격리, 죽은 프로세스의 재시작 허용, 프로덕션 환경에서 시스템 동작의 측정, 모니터링, 분석하기, 시스템이 보장하길 바라는 어떤 것에 대해 수행 중 지속적으로 확인하고 차이가 생기는 경우 경고 발생시키기

3. 인적 오류

   - 사람은 미덥지 않지만 (ㅋㅋ) 시스템을 신뢰성 있게 만들어야 한다.

   - 접근 방식들

     → 추상화, API, 관리 인터페이스를 잘 설계해야함 오류의 가능성을 최소화하도록 (하지만 또 지나치게 제한적이면 안됨)

     → 비 프로덕션 샌드박스를 제공하자. 사람의 실수로 장애가 발생할 수 있는 부분을 분리해서 실 사용자에게 영향이 미치지 않게 실험하도록.

     → 철저한 테스트 : 단위 테스트, 전체 시스템 통합 테스트, 수동 테스트, 자동 테스트, 코너 케이스 체크

     → 롤백, 롤아웃, 데이터 재계산 도구 등을 사용해서 복구가 빨리 되도록 한다.

     → 상세하고 명확한 모니터링 : 성능 지표, 오류율 확인

     > 모니터링을 원격 측정(telemetry)라고 부르기도 한다.
     >
     > 문제 발생 시 지표(metrics)는 문제 분석 시 매우 중요하다

     → 조작 교육과 실습을 시행하라. 까다롭지만 중요하다.

4. 그래서

   신뢰성은 중요하다.

   비용을 줄여서 신뢰성을 희생하는 경우가 있지만 그게 어느 선까지 허용되는지 잘 알아야 한다.

<br>

### 확장성

- 현재의 안정적인 동작이 미래의 안정성을 보장하지 않는다.

- 성능 저하의 가장 흔한 이유는 **부하 증가**다.

- 확장성은 **부하가 증가할 때 대처하는 시스템 능력**이지만, 일차원적인 표식이 아니다.

  확장성을 논한다는건 *A는 확장 가능하다. 확장성이 없다* 따위가 아니라, *시스템이 특정 방식으로 커지면 이에 대처하기 위한 선택은 무엇인가?, 추가 부하를 다루기 위해 계산 자원을 어떻게 투입할까?*와 같은 것을 고려하는 것이다.

1. 부하 기술하기

   - 시스템의 부하를 간결하게 기술해야 부하가 성장했을때의 논의를 진행할 수 있다.

   - 그래서 부하를 어떻게 나타내냐? 

     → 부하 매개변수를 사용

   - 적합한 부하 매개변수는 시스템 설계에 따라 달라진다. (진리의 케바케)

     > 가능한 부하 매개변수 : 웹 서버의 초당 요청 수, 데이터베이스의 읽기 대 쓰기 비율, 대화방의 동시 활성 사용자, 캐시 적중률 등

   - 평균적인 경우가 중요할 수도 있고, 소수의 극단적인 경우가 병목 현상의 원인일 수도 있다.

     > 정말 딱 공통적인 시나리오 상황은 거의 없고 서비스나 실제 시스템 상황을 잘 연구하고 그거에 맞춰서 적절한 해결법을 고안해야 되는구나 하는 생각이 든다

   - ***트위터 사례***

     - 트위터의 주요 동작
       1. 트윗 작성 : 팔로워에게 새로운 메시지를 게시 (평균 초당 4.6K 요청, 피크 시 초당 12K이상)
       2. 홈 타임라인 : 팔로우한 사람이 작성한 트윗 보기(평균 초당 300K 요청)
       
     - 단순한 초당 12K 작성 요청 처리는 쉽다. 그러나 확장성과 관련되어 발생하는 문제는 트윗 양보다는 팬아웃이다.
     
       > 팬 아웃 - 트랜잭션 처리 시스템에서 하나의 수신 요청을 처리하는데 필요한 다른 서비스의 요청 수와 관련되어 있다.
     
     - 트윗 작성시 팔로워의 홈 타임라인 구현 방법
     
       1. 새로운 트윗을 트윗 전역 컬렉션에 삽입. 
     
          홈 타임라인 읽기 요청시 팔로우 하는 모든 사람을 찾고 이들의 모든 트윗을 찾아서 정렬하고 합침
     
       2. 개별 사용자마다 홈 타임라인 캐시를 유지
     
          새로운 트윗 작성 시 해당 사용자를 팔로우 하는 모든 사람을 찾고, 그들의 홈 타임라인 캐시에 삽입. 
     
          → 쓰기 시점에 많은 일을 함 (트윗 작성, 부가 작업 - 캐시에 삽입)
     
          홈 타임라인 읽기 요청 시 미리 계산한 효과. 비용이 저렴하다.
     
          → 읽기 시점에 적은 일을 함
     
     - 트위터의 홈 타임라인 구현 방식의 변화
     
       → 원래는 1번 방식을 사용했지만, 질의 부하가 너무 컸다.
     
       → 그래서 2번 방식으로 변경했는데, 게시 요청량이 타임라인 읽기 요청량보다 훨씬 적으므로 잘 동작함.
     
       2번 방식에는 단점이 있는데, 팔로워 수가 많은 경우 일이 너무 많아짐. 예를 들면 팔로워가 3천만명인 경우 3천만번의 쓰기 요청 필요함
     
       → 그래서 1번과 2번을 섞어 쓰기로 했다. 팔로워 수가많은 경우 1번 방식, 대부분의 사용자는 2번 방식을 사용
     
     - 팬아웃 부하를 결정하는 것은 사용자의 팔로워 분포임. 따라서 이 팔로워의 분포가 핵심 매개변수가 된다.

2. 성능 기술하기

   - 부하가 증가하는 경우 (부하 매개변수 값이 증가)

     1. **자원**을 변경하지 않고 유지한다면 / **성능**이 받는 영향 ?
     2. **성능**이 변하지 않고 유지되려면 / **자원**을 얼마나 많이 늘려야 할까 ? 

     > 자원이란 : CPU, 메모리, 네트워크 대역폭 등

     이 질문에 대해 답을 찾기 위해서는 **성능 수치**가 필요하다. 알아보자 !

   - 시스템 성능 수치

     1. 처리량 (Throughput)

        - 하둡같은 일괄 처리 시스템이 관심 갖는 수치임

          > - 초당 처리할 수 있는 레코드 수
          > - 일정 크기의 데이터 집합으로 작업을 수행할 때 걸리는 전체 시간

     2. 응답 시간 (Response time)

        - 클라이언트가 요청을 보내고 응답을 받는 사이의 시간
        - 온라인 시스템에서 중요한 사항임

        > 지연 시간(latency)은 비슷하지만 같은 것은 아니다. 
        >
        > 클라이언트 관점에서 본 시간이 응답 시간이고, 응답 시간에는 요청을 실제 처리하는 시간, 여러 가지 지연 등이 포함될 수 있다.
        >
        > 지연 시간의 가능한 경우들
        >
        > - 네트워크 지연, 큐 지연, 백그라운드 프로레스의 컨텍스트 스위치, 네트워크 패킷 손실과 TCP 재전송, CG pause, 디스크에서 강제로 읽어오는 page fault, 서버 랙의 기계적 진동 등

        - 클라이언트가 같은 요청을 보내더라도 응답시간이 달라질 수 있다. 따라서 응답 시간은 단일 값이 아닌 측정 가능한 값의 분포로 본다.

        - 특이 값(outlier)가 존재하므로 산술 평균 값은 사용하기 적절한 수치가 아니다.

          대신 백분위를 사용한다. `p{숫자}`로 표현한다.

          >  p50 : 중앙값

        - 상위 백분위 응답 시간

          p95, p99, p999 : 요청의 95%, 99%, 99.9%에 해당하는 값.

          p99 → 요청의 99%가 이 값보다 빠르게 처리됨. 요청 100개 중 99개는 이 값보다 빠르게 처리됨.

          꼬리 지연 시간(tail latency)라고도 함. 서비스의 사용자 경험에 직접 영향을 미치므로 중요하다.

        - 서비스 수준 목표(SLO), 서비스 수준 협약서(SLA) 등에서 기대 성능을 정의할 때 많이 사용

        - 큐 대기 지연은 응답 시간이 오래 걸리는 큰 원인이다. 소수의 느린 요청이 뒤의 요청을 지체시킬 경우 선두차단(head-of-line blocking)이라고 한다.

3. 부하 대응 접근 방식

   - 확장성과 관련된 작업들

     1. scale up
     2. scale out
     3. shared-nothing (비공유 확장, 다수에 장비에 부하를 분산)

   - 범용적(one-size-fits-all) 확장 아키텍쳐는 없다. 특정 어플리케이션의 주요 동작과 잘 하지 않는 동작을 고려해야 한다.

     > 읽기의 양, 쓰기의 양, 저장할 데이터의 양, 데이터의 복잡도, 응답시간 요구사항, 접근 패턴 등

     이런 동작의 가정은 곧 **부하 매개변수**이며, 아키텍쳐 설계 시에 바탕이 되므로 중요하다. 

   - 예를 들면 1kb 파일의 초당 100,000건의 요청 처리를 위한 시스템과 2GB 파일의 분당 3건 요청 처리를 위한 시스템은 설계가 완전히 다르다.ㅉ

<br>

### 유지보수성

- 소프트웨어 시스템을 설계할 때의 원칙 : 운용성, 단순성, 발전성.
- 위에서 제시한 신뢰성과 확장성을 달성하기는 쉽지 않다. 그보다는 유지보수성을 염두해 두고 시스템을 설계해야 한다.

1. 운용성: 운영의 편리함 만들기

   - 운영팀이 시스템을 편하게 운영할 수 있도록 하는 것. 
   - 모니터링, 자동화, 보안 패치 등

2. 단순성: 복잡도 관리

   - 복잡도의 예시 : 상태 공간의 급증, 강하게 커플링 되어 있는 모듈, 복잡한 의존성, 일관성 없는 네이밍과 용어, 성능 문제 해결을 목표로 한 해킹, 임시방편으로 문제를 해결한 특수 사례 등

   - 단순성 != 시스템의 기능 줄이기

     단순성 == 우발적인 복잡도 줄이기 (구현에서 발생하는 문제)

   - 추상화를 통해서 우발적인 복잡도를 줄일 수 있다. 세부 구현을 숨기며 재사용성을 높인다.

3. 발전성: 변화를 쉽게 만들기

   - 요구사항은 반드시 바뀐다.
   - 애자일, TDD, 리팩토링
   - 발전성은 단순성과 추상화와 관련이 있다.

<br>

### 정리

애플리케이션이 충족시켜야 하는 요구사항

1. 기능적 요구사항

2. 비기능적 요구사항

   > 보안, 신뢰성, 법규 준수, 확장성, 호환성, 유지보수성 등

   여기서 집중해서 본 것은 신뢰성, 확장성, 유지보수성이다.

   - 신뢰성 : 결함이 발생해도 시스템은 올바르게 돌아감
   - 확장성 : 부하가 증가해도 좋은 성능을 유지
   - 유지보수성 : 운영 편하게 하기, 추상화를 잘하기, 요구사항 변화에 잘 대처하기

<br>

## 02 데이터 모델과 질의 언어

데이터 모델은 소프트웨어 개발에서 제일 중요한 부분이다. 해결해야 하는 문제를 어떻게 생각할 지에 큰 영향을 미치기 때문이다. 

애플리케이션에서는 여러 층의 데이터 모델을 사용하여 복잡성을 숨긴다. 데이터 모델의 유형은 굉장히 다양하고, 사용 방법 또한 그러하다. 데이터 모델은 소프트웨어가 할 수 있는 일과 할 수 없는 일에 큰 영향을 미치므로, 애플리케이션에 적합한 데이터 모델을 선택하는 작업은 매우 중요하다.

따라서 여기서는 여러 데이터 모델을 비교하여 살펴본다.

### 관계형 모델과 문서 모델

<br>

## 03 저장소와 검색

<br>

## 04 부호화와 발전

<br>

## 2장 분산 데이터

<br>

## 05 복제

<br>

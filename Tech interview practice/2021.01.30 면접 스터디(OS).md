### OS 기술면접 스터디

<div align="center">
   <img src="https://user-images.githubusercontent.com/41130448/106348265-4563f900-6308-11eb-9638-43df4f14a19a.png" width="40%"></img>
</div>

1. 프로세스란?

   실제 실행중인 프로그램으로, 메모리에 코드와 데이터, 스택, 힙이 적재되어 있고, CPU를 점유하는 인스턴스

2. 스택에는 어떤 정보가 들어 있는가?

   함수 호출 시 전달되는 인자, 리턴될 주소 값, 함수 내의 지역 변수 등이 저장

3. PCB에는 프로세스의 어떤 정보가 저장되어 있는가?

   식별자(pid), 프로세스 상태, PC, CPU 레지스터, 스케쥴링 정보, 페이지 테이블 정보, accounting 정보(cpu 점유 시간 등)

4. 프로세스 state를 설명해보세용

   처음에 생성되면 new, 메모리에 적재되고 CPU에 할당될 준비가 되면 ready queue에 넣음, dispatch되어 running 상태로 가면 실행됨, 정해진 시간이 다되면 timer INT로 ready 상태로 돌아감. 혹은 I/O event 발생시 CPU를 놓고 waiting 상태에서 I/O가 끝나길 기다림. I/O가 끝나면 ready 상태로 감. 실행이 다 끝나면 exit call로 terminated 상태가 되며, 이 상태를 거쳐 상태 정보가 해제된다.

5. 프로그램 실행 과정 : 

   로드(시작 지점 메모리에 가져옴), 패치(메모리에 가져온 명령어들을 cpu로 가져옴) 디코드(cpu에서 실행할 수있는 언어로 명령어를 변환), 실행(cpu의 alu에서 decode된 명령어를 실행함)

6. 스레드란?

   프로세스 내에서 실행되는 흐름의 단위, CPU를 실행하는 흐름이기 때문에 CPU 입장에서는 비슷

7. 프로세스와 스레드의 차이점은?

   가지고 있는 정보가 다름, 프로세스는 각각이 독립적임, 스레드는 프로세스 내에서 여러 개가 존재할 수 있으며, 이들은 서로 프로세스 내의 공유 자원이 존재한다. 스레드가 독립적으로 갖는 것은 스레드 아이디, 스택 포인터와 CPU 레지스터, Program counter임

8. 스레드를 사용했을 때 갖는 이점은? 멀티 스레딩의 이점

   새로운 프로세스를 생성하는 것보다 새로운 스레드를 생성하는 것이 시간적, 메모리적으로 훨씬 절약할 수 있음. context switch를 할 때 캐시 메모리를 비울 필요가 없으며, 독립적으로 갖는 자원의 할당량이 프로세스보다 적기 때문에 걸리는 시간이 단축됨. 프로세스끼리 소통할 때에는 메시지 패싱이나 공유 메모리 등 IPC 방법을 사용해 통신해야 하는 것에 비해 스레드는 프로세스 내부에서 서로 데이터 공간과 힙 공간을 공유하므로 통신이 간단하다. 

9. 멀티 스레딩의 문제점

   공유 영역이 있으므로, 사용중인 데이터에 대해서 동기화 작업을 해주어야 한다. 오류로 인해 스레드 하나가 종료되면, 전체 스레드가 종료될 수 있다. 멀티 프로세스 환경에서는 하나의 프로세스가 오류가 나도 다른 프로세스에는 오류를 내지 않는다. 

10. 좀비 프로세스와 고아 프로세스

    *좀비 프로세스*

    할일을 다했지만 자원이 회수되지 않은 프로세스, parent process가 wait으로 collect하지 않음. 모든 프로세스는 얼마간 좀비 프로세스로 존재하고, wait call이 일어나면 정상적으로 종료됨.

    *고아 프로세스*

    parent가 wait으로 회수하지 않고, 먼저 종료된 것. child는 실행중임. 

    유닉스에서는 init process가 적당히 돌면서 exit status를 체크하고, wait call을 invoke해서 해당 고아 프로세스를 회수한다.

11. fork와 exec의 차이

12. cow(copy on write)

    page table만 copy

13. 프로세스 스케쥴링에 필요한 세가지 큐의 종류

    1) job queue: 현재 시스템 내에 있는 모든 프로세스

    2) ready queue: 현재 메모리 내에 존재, cpu의 실행을 기다림

    3) device queue: device I/O 작업을 대기하고 있는 프로세스

14. 각 종류의 큐에 프로세스를 할당하는 스케쥴러의 종류

    1) 장기 스케쥴러: 디스크에서 메모리로 올릴 프로세스를 담당

    2) 단기 스케쥴러: 메모리에서 CPU로 올릴 프로세스를 담당

    3) 중기 스케쥴러: 메모리에서 디스크로 내릴 프로세스를 담당, 해당 프로세스는 suspended state가 됨 (block state는 I/O를 기다리는 상태임)

15. CPU 스케쥴러의 종류

    1. FCFS (First Come First Served)

       비선점형, Convoy effect 발생 가능

    2. SJF (Shortest Job First)

       비선점형, starvation 발생 가능

    3. SRTF (Shortest Remaining Time First)

       선점형 SJF, starvation 발생 가능

    4. Priority scheduling

       선점형/비선점형 가능, startvation 발생 가능 (aging으로 해결)

    5. Round robin

       선점형, 일정 time quantum을 지내고 다른 프로세스로 교체

       response time이 빨라짐, time quantum이 너무 커지면 FCFS가 되버림, 너무 작아지면 잦은 context switch로 오버에드 발생

    6. Multi level queue

       선점형, 각 우선순위별로 다른 time quantum을 지정함

       우선순위가 높을 수록 작은 time quantum

    7. Multi level feedback queue

       multilevel queue에서 우선순위를 변화시키는 정책을 추가한 것. 주어진 time quantum을 다 채운 후에도 작업이 완료되지 못하면 우선순위를 낮춘다. 

16. CPU 스케쥴링의 척도

    1. response time : 작업 요청이 들어온 후 처음 실행되기 까지의 시간
    2. turnaround time : 작업 요청이 들어온 후 작업이 완료되기까지 걸린 시간

17. 동기화는 왜 하는지

    멀티 스레딩 환경에서 공유 자원이 존재함. 동일한 자원에 대해 동일한 접근을 하는 경우 문제가 생길 수 있기 때문에 동기화를 진행. 

18. 크리티컬 섹션이란

    동기화의 대상이 되는 영역. 여러 스레드가 동시에 접근할 경우 문제가 발생할 수 있는 코드 영역. 

19. 크리티컬 섹션 문제를 풀기 위해 필요한 전제

    1. mutual exclusion 누가 들어 있으면 다른 애가 못들어감
    2. progress 아무도 안들어 있는데 누군가 들어가고 싶으면 들어갈 수 있다는 것을 보장
    3. bounded waiting 균등하게 들어갈 수 있도록 하는 특정 bound가 필요하다.

20. Peterson's solution에 대해서 간단히 설명

    SW 기법으로, CS 문제를 풀기 위한 세가지 전제를 만족함

    단점; busy-waiting 기법에 기반하므로 CPU를 계속 소모함, 현대 아키텍쳐에서는 코드 간에 의존성이 없으면 순서를 재배치하므로 문제가 생길 수 있음. 코드 상에서는 피터슨 알고리즘에서 사용하는 변수가 서로 의존성이 없어 보이기 때문

    memory barrier 기법으로 해결 가능

21. CS 문제 풀기 위한 HW 기법은

    Test and set/ Compare and swap

    lock 변수를 사용, 하드웨어 적으로 atomic하게 실행되도록 만들어 놓은 instruction들

22. concurrency와 parallelism의 차이점

    concurrency는 동시에 여러 작업을 진행하는 것이고, parallelism은 한 작업을 여러개의 하위 작업으로 나누어서 동시에 수행하는 것.

    concurrency는 논리적 level이기 때문에 single core에서 multitasking을 수행하는 것도 동시성을 실행했다고 봄. 실제 물리적으로 병렬적 작업을 하는 multicore에서의 task 수행도 당연히 동시성을 갖고 있다고 함. 

    parallelism은 실제 물리적 level에서 동시에 작업을 처리하는 것을 의미. 

23. 뮤텍스와 세마포

    1. 뮤텍스 

       - 공유 자원을 여러 스레드가 접근하지 못하도록 막음
       - lock을 사용
       - busy waiting 기법 사용 (spinlock)

    2. 세마포

       - 공유 자원의 데이터를 여러 프로세스가 접근하는 것을 막음
       - 리소스 상태를 나타내는 카운터로 생각할 수 있음
       - 접근할 수 있는 프로세스의 허용 수치를 지정할 수 있음

    3. 차이점

       - 동기화 대상의 개수 

         뮤텍스는 동기화 대상이 하나, 세마포는 동기화 대상이 하나 이상

         상태 값이 0, 1 두 개밖에 가질 수 없는 세마포를 뮤텍스라고 생각할 수 있음

24. 교착 상태란

    두 스레드가 서로 락을 가지고 있으며 상대 스레드가 가지고 있는 객체의 락이 풀리기를 기다리고 있는 상태. 무한히 대기하는 상태가 됨.

25. 교착 상태의 조건

    1. 상호 배제 : 한번에 한 프로세스만 공유 자원 사용 가능
    2. 점유 대기 : 어떤 접근 권한 가지고 있는 상태에서 다른 자원에 대한 접근 권한 요구 가능
    3. 비선점 : 다른 프로세스의 접근 권한을 강제로 취소시킬 수 없음
    4. 순환 대기 : 두 개 이상의 프로세스가 자원 접근을 기다릴 때, 대기 상태의 사이클 존재함

26. 교착 상태를 방지하기 위해서는

    교착 상태의 조건 중 하나를 제거하면 된다. 

27. Thrashing

    프로세스 처리 시간보다 페이지 교체 되는 시간이 많아서 cpu 이용율이 떨어지는 것..  page fault가 많이 발생할 때 일어나는 것

28. 사용자 공간 스레드 / 커널 공간 스레드 

29. priority boost

    multi level feedback queue에서 특정 시간이 지난 후 모든 작업을 최상단 우선 순위로 모두 배치하는 것, aging이랑은 다르지만 starvation을 방지하는 방법으로 사용할 수 있음

30. 메모리 할당 알고리즘 - first fit, 처음부터 쭉 검색하다가 넣을 수 있는 공간이 나오면 배치하는 방식 best fit 모든 메모리를 스캔하고 프로세스가 들어갈 수 있는 가장 좁은 공간 찾기 worst fit 스캔하는 것은 똑같은데 들어갈 수 있는 가장 큰 공간 찾아서 적재 
